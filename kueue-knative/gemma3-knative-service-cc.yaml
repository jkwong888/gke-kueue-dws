apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: gemma3-vllm
spec:
  template:
    spec:
      nodeSelector:
        cloud.google.com/compute-class: gemma3-inf-nodes
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      containers:
        - name: vllm
          command:
          - python3
          - -m
          - vllm.entrypoints.openai.api_server
          - --port 8000
          - --model 
          - google/gemma-3-4b-it
          image: vllm/vllm-openai:latest
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 240
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          ports:
            - containerPort: 8000
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 240
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              nvidia.com/gpu: "1"
            limits:
              nvidia.com/gpu: "1"
