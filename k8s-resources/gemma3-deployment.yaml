apiVersion: apps/v1
kind: Deployment
metadata:
  name: gemma3-vllm
spec:
  selector:
    matchLabels:
      app: gemma3-vllm
  template:
    metadata:
      labels:
        app: gemma3-vllm
    spec:
      nodeSelector:
        cloud.google.com/compute-class: gemma3-inf-nodes
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      containers:
        - name: vllm
          tty: true
          stdin: true
          command:
          - python3
          - -m
          - vllm.entrypoints.openai.api_server
          - --port=$(PORT)
          - --model=$(HF_HOME)/$(MODEL_NAME)
          # - --model=$(MODEL_NAME)
          env:
          # - name: VLLM_LOGGING_LEVEL
          #   value: DEBUG
          # - name: HUGGING_FACE_HUB_TOKEN
          #   valueFrom:
          #     secretKeyRef:
          #       name: hf-token
          #       key: token
          - name: LD_LIBRARY_PATH
            value: "/usr/local/nvidia/lib64:/usr/local/lib/"
          - name: HF_HUB_OFFLINE
            value: "1"
          - name: PORT
            value: "8000"
          - name: MODEL_NAME
            value: google/gemma-3-4b-it
          - name: HF_HOME  
            value: /opt/model-data/models
          - name: VLLM_CACHE_ROOT
            value: /opt/model-data/cache
          image: vllm/vllm-openai:latest
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 240
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          ports:
            - containerPort: 8000
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 240
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              nvidia.com/gpu: "1"
            limits:
              nvidia.com/gpu: "1"
          volumeMounts:
          - name: library-dir-host
            mountPath: /usr/local/nvidia
          - name: dshm
            mountPath: /dev/shm
          - name: model-data
            mountPath: /opt/model-data
      volumes:  
      - name: library-dir-host  # use the nvidia drivers installed in the host
        hostPath:
          path: /home/kubernetes/bin/nvidia
      - name: dshm
        emptyDir:
          medium: Memory
      - name: model-data
        hostPath:
          path: /mnt/disks/gke-secondary-disks/gke-packer-1755110063-disk
          type: Directory

